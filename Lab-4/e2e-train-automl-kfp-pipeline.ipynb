{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec58683-01ac-47bb-95ab-6c3c931e20e0",
   "metadata": {},
   "source": [
    "# E2E ML Vertex KFP Pipeline with AutoML\n",
    "\n",
    "### Daataset\n",
    "UCI Machine Learning [Dry beans dataset](https://archive.ics.uci.edu/dataset/602/dry+bean+dataset)\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "- Create a Dataset in {{vertex_ai_name}}\n",
    "- Train a tabular classification model with AutoML\n",
    "- Get evaluation metrics on this model\n",
    "- Based on the evaluation metrics, decide whether to deploy the model using conditional logic in Vertex Pipelines\n",
    "- Deploy the model to an endpoint using Vertex Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136d3d8-2496-40b1-9353-76968c75e6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "YOUR_NAME=\"your-name\" # TO-DO: store your name in this var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4808a8-e8e6-4e82-8deb-607536ef476b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --user google-cloud-aiplatform==1.50.0 kfp==2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a5232-cb85-4c1f-8f36-2e5f7391028f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --user google-cloud-pipeline-components --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953cf39-a276-4012-b3cc-d9fbe1f30c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "\n",
    "from kfp import compiler, dsl\n",
    "from kfp.dsl import component, pipeline, Artifact, ClassificationMetrics, Input, Output, Model, Metrics\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc57a6-8812-420b-8a55-5282d00cd60e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID='mlops-421501'\n",
    "BUCKET=f\"gs://{PROJECT_ID}-{YOUR_NAME}-bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c8ddc1-3165-4575-9969-460c72a5937f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-central1\"\n",
    "\n",
    "PIPELINE_ROOT = f\"{BUCKET}/pipeline_root/\"\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d6e026-257c-4518-9e48-0ad948ba681b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components import v1 as gcc_aip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7fc95-e92d-4e97-b914-df206e0ad65e",
   "metadata": {},
   "source": [
    "### Build Custom Component for Model Evaluation\n",
    "\n",
    "\n",
    "Function of the component:\n",
    "- Get the evaluation metrics from the trained AutoML classification model\n",
    "- Parse the metrics and render them in the Vertex Pipelines UI\n",
    "- Compare the metrics to a threshold to determine whether the model should be deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5a117-5e16-430b-8d53-ee1b81511dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest\",\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    ")\n",
    "def classification_model_eval_metrics(\n",
    "    project: str,\n",
    "    location: str,  # \"us-central1\",\n",
    "    thresholds_dict_str: str,\n",
    "    model: Input[Artifact],\n",
    "    metrics: Output[Metrics],\n",
    "    metricsc: Output[ClassificationMetrics],\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    ") -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):  # Return parameter.\n",
    "\n",
    "    import json\n",
    "    import logging\n",
    "\n",
    "    from google.cloud import aiplatform as aip\n",
    "\n",
    "    # Fetch model eval info\n",
    "    def get_eval_info(client, model_name):\n",
    "        from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "        response = client.list_model_evaluations(parent=model_name)\n",
    "        metrics_list = []\n",
    "        metrics_string_list = []\n",
    "        for evaluation in response:\n",
    "            print(\"model_evaluation\")\n",
    "            print(\" name:\", evaluation.name)\n",
    "            print(\" metrics_schema_uri:\", evaluation.metrics_schema_uri)\n",
    "            metrics = MessageToDict(evaluation._pb.metrics)\n",
    "            for metric in metrics.keys():\n",
    "                logging.info(\"metric: %s, value: %s\", metric, metrics[metric])\n",
    "            metrics_str = json.dumps(metrics)\n",
    "            metrics_list.append(metrics)\n",
    "            metrics_string_list.append(metrics_str)\n",
    "\n",
    "        return (\n",
    "            evaluation.name,\n",
    "            metrics_list,\n",
    "            metrics_string_list,\n",
    "        )\n",
    "\n",
    "    # Use the given metrics threshold(s) to determine whether the model is\n",
    "    # accurate enough to deploy.\n",
    "    def classification_thresholds_check(metrics_dict, thresholds_dict):\n",
    "        for k, v in thresholds_dict.items():\n",
    "            logging.info(\"k {}, v {}\".format(k, v))\n",
    "            if k in [\"auRoc\", \"auPrc\"]:  # higher is better\n",
    "                if metrics_dict[k] < v:  # if under threshold, don't deploy\n",
    "                    logging.info(\"{} < {}; returning False\".format(metrics_dict[k], v))\n",
    "                    return False\n",
    "        logging.info(\"threshold checks passed.\")\n",
    "        return True\n",
    "\n",
    "    def log_metrics(metrics_list, metricsc):\n",
    "        test_confusion_matrix = metrics_list[0][\"confusionMatrix\"]\n",
    "        logging.info(\"rows: %s\", test_confusion_matrix[\"rows\"])\n",
    "\n",
    "        # log the ROC curve\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        thresholds = []\n",
    "        for item in metrics_list[0][\"confidenceMetrics\"]:\n",
    "            fpr.append(item.get(\"falsePositiveRate\", 0.0))\n",
    "            tpr.append(item.get(\"recall\", 0.0))\n",
    "            thresholds.append(item.get(\"confidenceThreshold\", 0.0))\n",
    "        print(f\"fpr: {fpr}\")\n",
    "        print(f\"tpr: {tpr}\")\n",
    "        print(f\"thresholds: {thresholds}\")\n",
    "        metricsc.log_roc_curve(fpr, tpr, thresholds)\n",
    "\n",
    "        # log the confusion matrix\n",
    "        annotations = []\n",
    "        for item in test_confusion_matrix[\"annotationSpecs\"]:\n",
    "            annotations.append(item[\"displayName\"])\n",
    "        logging.info(\"confusion matrix annotations: %s\", annotations)\n",
    "        metricsc.log_confusion_matrix(\n",
    "            annotations,\n",
    "            test_confusion_matrix[\"rows\"],\n",
    "        )\n",
    "\n",
    "        # log textual metrics info as well\n",
    "        for metric in metrics_list[0].keys():\n",
    "            if metric != \"confidenceMetrics\":\n",
    "                val_string = json.dumps(metrics_list[0][metric])\n",
    "                metrics.log_metric(metric, val_string)\n",
    "        # metrics.metadata[\"model_type\"] = \"AutoML Tabular classification\"\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    aip.init(project=project)\n",
    "    # extract the model resource name from the input Model Artifact\n",
    "    model_resource_path = model.metadata[\"resourceName\"]\n",
    "    logging.info(\"model path: %s\", model_resource_path)\n",
    "\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    client = aip.gapic.ModelServiceClient(client_options=client_options)\n",
    "    eval_name, metrics_list, metrics_str_list = get_eval_info(\n",
    "        client, model_resource_path\n",
    "    )\n",
    "    logging.info(\"got evaluation name: %s\", eval_name)\n",
    "    logging.info(\"got metrics list: %s\", metrics_list)\n",
    "    log_metrics(metrics_list, metricsc)\n",
    "\n",
    "    thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    deploy = classification_thresholds_check(metrics_list[0], thresholds_dict)\n",
    "    if deploy:\n",
    "        dep_decision = \"true\"\n",
    "    else:\n",
    "        dep_decision = \"false\"\n",
    "    logging.info(\"deployment decision is %s\", dep_decision)\n",
    "\n",
    "    return (dep_decision,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71fe2c2-05c2-4fe0-beb3-caf3e3519db8",
   "metadata": {},
   "source": [
    "### Define Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73946d57-b2db-487e-ac0b-1ebb2889d926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "DISPLAY_NAME = '{}-automl-beans{}'.format(YOUR_NAME,str(int(time.time())))\n",
    "print(DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02c916-1c76-4f30-a51e-814ed6c452fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PIPELINE_NAME= f\"{YOUR_NAME}-automl-tab-beans-training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc68ac-58d7-4635-a0f9-236b6457378e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=PIPELINE_NAME, pipeline_root=PIPELINE_ROOT)\n",
    "def pipeline(\n",
    "    bq_source: str,\n",
    "    DATASET_DISPLAY_NAME: str,\n",
    "    TRAINING_DISPLAY_NAME: str,\n",
    "    MODEL_DISPLAY_NAME: str,\n",
    "    ENDPOINT_DISPLAY_NAME: str,\n",
    "    MACHINE_TYPE: str,\n",
    "    project: str,\n",
    "    gcp_region: str,\n",
    "    thresholds_dict_str: str,\n",
    "):\n",
    "    from google_cloud_pipeline_components.v1.automl.training_job import \\\n",
    "        AutoMLTabularTrainingJobRunOp\n",
    "    from google_cloud_pipeline_components.v1.dataset.create_tabular_dataset.component import \\\n",
    "        tabular_dataset_create as TabularDatasetCreateOp\n",
    "    from google_cloud_pipeline_components.v1.endpoint.create_endpoint.component import \\\n",
    "        endpoint_create as EndpointCreateOp\n",
    "    from google_cloud_pipeline_components.v1.endpoint.deploy_model.component import \\\n",
    "        model_deploy as ModelDeployOp\n",
    "\n",
    "    dataset_create_op = TabularDatasetCreateOp(\n",
    "        project=project,\n",
    "        location=gcp_region,\n",
    "        display_name=DATASET_DISPLAY_NAME,\n",
    "        bq_source=bq_source,\n",
    "    ).set_display_name(\"Create Tabular Dataset\")\n",
    "\n",
    "    training_op = AutoMLTabularTrainingJobRunOp(\n",
    "        project=project,\n",
    "        location=gcp_region,\n",
    "        display_name=TRAINING_DISPLAY_NAME,\n",
    "        optimization_prediction_type=\"classification\",\n",
    "        optimization_objective=\"minimize-log-loss\",\n",
    "        budget_milli_node_hours=1000,\n",
    "        model_display_name=MODEL_DISPLAY_NAME,\n",
    "        column_specs={\n",
    "            \"Area\": \"numeric\",\n",
    "            \"Perimeter\": \"numeric\",\n",
    "            \"MajorAxisLength\": \"numeric\",\n",
    "            \"MinorAxisLength\": \"numeric\",\n",
    "            \"AspectRation\": \"numeric\",\n",
    "            \"Eccentricity\": \"numeric\",\n",
    "            \"ConvexArea\": \"numeric\",\n",
    "            \"EquivDiameter\": \"numeric\",\n",
    "            \"Extent\": \"numeric\",\n",
    "            \"Solidity\": \"numeric\",\n",
    "            \"roundness\": \"numeric\",\n",
    "            \"Compactness\": \"numeric\",\n",
    "            \"ShapeFactor1\": \"numeric\",\n",
    "            \"ShapeFactor2\": \"numeric\",\n",
    "            \"ShapeFactor3\": \"numeric\",\n",
    "            \"ShapeFactor4\": \"numeric\",\n",
    "            \"Class\": \"categorical\",\n",
    "        },\n",
    "        dataset=dataset_create_op.outputs[\"dataset\"],\n",
    "        target_column=\"Class\",\n",
    "    ).set_display_name(\"AutoML Training Job\")\n",
    "\n",
    "    model_eval_task = classification_model_eval_metrics(\n",
    "        project=project,\n",
    "        location=\"us-central1\",\n",
    "        thresholds_dict_str=thresholds_dict_str,\n",
    "        model=training_op.outputs[\"model\"],\n",
    "        api_endpoint=\"us-central1-aiplatform.googleapis.com\"\n",
    "    ).set_display_name(\"Evaluation Metrics\")\n",
    "\n",
    "    with dsl.If(\n",
    "        model_eval_task.outputs[\"dep_decision\"] == \"true\",\n",
    "        name=\"deploy_decision\",\n",
    "    ):\n",
    "\n",
    "        endpoint_op = EndpointCreateOp(\n",
    "            project=project,\n",
    "            location=gcp_region,\n",
    "            display_name=ENDPOINT_DISPLAY_NAME,\n",
    "        ).set_display_name(\"Create Endpoint\")\n",
    "\n",
    "        ModelDeployOp(\n",
    "            model=training_op.outputs[\"model\"],\n",
    "            endpoint=endpoint_op.outputs[\"endpoint\"],\n",
    "            dedicated_resources_min_replica_count=1,\n",
    "            dedicated_resources_max_replica_count=1,\n",
    "            dedicated_resources_machine_type=MACHINE_TYPE,\n",
    "        ).set_display_name(\"Deploy to Endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee7c9df-c96a-4138-b644-52152971c00b",
   "metadata": {},
   "source": [
    "### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c52323-60b9-4b4d-9faf-14177fccd18c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"tab_classif_pipeline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb57b141-75d8-4f34-88ad-0e306ed13f08",
   "metadata": {},
   "source": [
    "### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed0619-e531-432b-98ee-8f452cad898d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bq_source=\"bq://aju-dev-demos.beans.beans1\"\n",
    "gcp_region= \"us-central1\"\n",
    "api_endpoint=\"us-central1-aiplatform.googleapis.com\"\n",
    "thresholds_dict_str='{\"auRoc\": 0.95}'\n",
    "DATASET_DISPLAY_NAME=f\"{YOUR_NAME}_dataset_beans\"\n",
    "TRAINING_DISPLAY_NAME=f\"{YOUR_NAME}_automl_training_beans\"\n",
    "MODEL_DISPLAY_NAME=f\"{YOUR_NAME}_model_beans\"\n",
    "ENDPOINT_DISPLAY_NAME=f\"{YOUR_NAME}_endpoint_beans\"\n",
    "MACHINE_TYPE=\"n1-standard-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb08ccc-8433-4961-8f63-3b0523efb5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml_pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name=f\"{YOUR_NAME}automl-tab-beans-training\",\n",
    "    template_path=\"tab_classif_pipeline.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\n",
    "        \"project\": PROJECT_ID,\n",
    "        \"gcp_region\": gcp_region,\n",
    "        \"bq_source\": bq_source,\n",
    "        \"thresholds_dict_str\": '{\"auRoc\": 0.95}',\n",
    "        \"DATASET_DISPLAY_NAME\": DATASET_DISPLAY_NAME,\n",
    "        \"TRAINING_DISPLAY_NAME\": TRAINING_DISPLAY_NAME,\n",
    "        \"MODEL_DISPLAY_NAME\": MODEL_DISPLAY_NAME,\n",
    "        \"ENDPOINT_DISPLAY_NAME\": ENDPOINT_DISPLAY_NAME,\n",
    "        \"MACHINE_TYPE\": MACHINE_TYPE,\n",
    "    },\n",
    "    enable_caching=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec3d8c-5d58-4d40-ae24-035089bfdea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml_pipeline_job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910a7d7-2b53-4750-aa51-d9a84b1515d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m120"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
